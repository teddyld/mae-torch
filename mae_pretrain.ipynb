{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Autoencoders Are Scalable Vision Learners (Pretrain)\n",
    "\n",
    "Conversion of mae_pretrain.py\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from model import *\n",
    "from utils import setup_seed, EarlyStopper, ImageDataset\n",
    "\n",
    "setup_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "batch_size = 128\n",
    "lr = 1.5e-4\n",
    "weight_decay = 0.05\n",
    "mask_ratio = 0.75\n",
    "num_epochs = 2000\n",
    "warmup_epoch = 200\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "test_tf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=train_tf)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = CIFAR10(root='./data', train=False, download=True, transform=test_tf)\n",
    "\n",
    "dataset_name = \"cifar10\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "test_tf = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "data_path = os.path.abspath(\"./data\")\n",
    "\n",
    "train_dataset = ImageDataset(root=data_path, train=True, transform=train_tf)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = ImageDataset(root=data_path, train=False, transform=test_tf)\n",
    "\n",
    "dataset_name = \"example\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_path = f\"./models/vit-t-mae-{dataset_name}.pt\"\n",
    "\n",
    "writer = SummaryWriter(os.path.join('logs', dataset_name, 'mae-pretrain'))\n",
    "model = MAE_ViT(mask_ratio=mask_ratio).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr * batch_size / 256, betas=(0.9, 0.95), weight_decay=weight_decay)\n",
    "\n",
    "lr_func = lambda epoch: min((epoch + 1) / (warmup_epoch + 1e-8), 0.5 * (math.cos(epoch / num_epochs * math.pi) + 1))\n",
    "lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_func)\n",
    "\n",
    "early_stopper = EarlyStopper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_run(model, optimizer, train_loader, val_dataset, lr_scheduler, early_stopper, num_epochs, mask_ratio, output_model_path):\n",
    "    print(f\"Training MAE on {DEVICE}\")\n",
    "    prev_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        print('.' * 64)\n",
    "        print(f\"--- Epoch {epoch + 1}/{num_epochs} ---\")\n",
    "        \n",
    "        model.train()\n",
    "        losses = []\n",
    "        pbar = tqdm(train_loader, leave=False)\n",
    "        for i, batch in enumerate(pbar):\n",
    "            img, label = batch\n",
    "            img = img.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            predicted_img, mask = model(img)\n",
    "            loss = torch.mean((predicted_img - img) ** 2 * mask) / mask_ratio\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # Determine approximate time left\n",
    "            batches_done = epoch * len(train_loader) + i\n",
    "            batches_left = num_epochs * len(train_loader) - batches_done\n",
    "            time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n",
    "            prev_time = time.time()\n",
    "        \n",
    "            pbar.set_description(f'Epoch [{epoch + 1}/{num_epochs}]')\n",
    "\n",
    "        # Update learning rate\n",
    "        prev_lr = lr_scheduler.get_last_lr()[0]\n",
    "        lr_scheduler.step()\n",
    "        curr_lr = lr_scheduler.get_last_lr()[0]\n",
    "        \n",
    "        if prev_lr > curr_lr:  \n",
    "            print(f'Updating lr {prev_lr}->{curr_lr}')\n",
    "        \n",
    "        \n",
    "        avg_loss = sum(losses) / len(losses)\n",
    "        writer.add_scalar('mae_loss', avg_loss, global_step=epoch)\n",
    "        \n",
    "        print(f\"train_loss: {avg_loss} ETA: {time_left}\")\n",
    "        \n",
    "        ''' Visualize the first 16 predicted images on val dataset'''\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_img = torch.stack([val_dataset[i][0] for i in range(16)])\n",
    "            val_img = val_img.to(DEVICE)\n",
    "            predicted_val_img, mask = model(val_img)\n",
    "            predicted_val_img = predicted_val_img * mask + val_img * (1 - mask)\n",
    "            img = torch.cat([val_img * (1 - mask), predicted_val_img, val_img], dim=0)\n",
    "            img = rearrange(img, '(v h1 w1) c h w -> c (h1 h) (w1 v w)', w1=2, v=3)\n",
    "            writer.add_image('mae_image', (img + 1) / 2, global_step=epoch)\n",
    "        \n",
    "        torch.save(model, output_model_path)\n",
    "        \n",
    "        # Early stopping\n",
    "        if early_stopper.early_stop(avg_loss):\n",
    "            print(f'Stopping early at Epoch {epoch + 1}, min loss failed to decrease after {early_stopper.get_patience()} epochs')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_run(model, optimizer, train_loader, val_dataset, lr_scheduler, early_stopper, num_epochs, mask_ratio, output_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
