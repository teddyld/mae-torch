{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Autoencoders Are Scalable Vision Learners (Classification)\n",
    "\n",
    "Conversion of train_classifier.py\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 16:40:36.031638: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-07 16:40:37.182694: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import *\n",
    "from utils import setup_seed, EarlyStopper, ImageDataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "setup_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "batch_size = 128\n",
    "lr = 1e-3\n",
    "weight_decay = 0.05\n",
    "num_epochs = 100\n",
    "warmup_epoch = 5\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "test_tf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "dataset_name = \"cifar10\"\n",
    "num_classes = 10 # CIFAR-10\n",
    "\n",
    "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=train_tf)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = CIFAR10(root='./data', train=False, download=True, transform=test_tf)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"example\"\n",
    "num_classes = 10\n",
    "\n",
    "train_dataset = ImageDataset(root='./data', train=True, transform=train_tf)\n",
    "val_dataset = ImageDataset(root='./data', train=False, transform=test_tf)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train from scratch\n",
    "model = MAE_ViT()\n",
    "writer = SummaryWriter(os.path.join('logs', dataset_name, 'scratch-cls'))\n",
    "output_model_path = f\"./models/vit-t-classifier-from_scratch-{dataset_name}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR Load pretrained model\n",
    "pretrained_model_path = f\"./models/vit-t-mae-{dataset_name}.pt\"\n",
    "model = torch.load(pretrained_model_path, map_location='cpu')\n",
    "writer = SummaryWriter(os.path.join('logs', dataset_name, 'pretrain-cls'))\n",
    "output_model_path = f\"./models/vit-t-classifier-from_pretrained-{dataset_name}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViT_Classifier(model.encoder, num_classes=num_classes).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr * batch_size / 256, betas=(0.9, 0.999), weight_decay=weight_decay)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "lr_func = lambda epoch: min((epoch + 1) / (warmup_epoch + 1e-8), 0.5 * (math.cos(epoch / num_epochs * math.pi) + 1))\n",
    "lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_func)\n",
    "\n",
    "acc_fn = lambda logit, label: torch.mean((logit.argmax(dim=-1) == label).float())\n",
    "early_stopper = EarlyStopper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_run(model, optimizer, train_loader, val_loader, criterion, acc_fn, lr_scheduler, early_stopper, num_epochs, output_model_path):\n",
    "    print(f\"Training MAE classification on {DEVICE}\")\n",
    "    best_accuracy_val = 0\n",
    "    prev_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        print('.' * 64)\n",
    "        print(f\"--- Epoch {epoch + 1}/{num_epochs} ---\")\n",
    "        \n",
    "        ''' Model training'''\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        train_accuracy = []\n",
    "        pbar = tqdm(train_loader, leave=False)\n",
    "        for i, batch in enumerate(pbar):\n",
    "            img, label = batch\n",
    "            img, label = img.to(DEVICE), label.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(img)\n",
    "            loss = criterion(logits, label)\n",
    "            acc = acc_fn(logits, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "            train_accuracy.append(acc.item())\n",
    "            \n",
    "            pbar.set_description(f'Epoch [{epoch + 1}/{num_epochs}]')\n",
    "            \n",
    "            # Determine approximate time left\n",
    "            batches_done = epoch * len(train_loader) + i\n",
    "            batches_left = num_epochs * len(train_loader) - batches_done\n",
    "            time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n",
    "            prev_time = time.time()\n",
    "\n",
    "        avg_train_loss = sum(train_loss) / len(train_loss)\n",
    "        avg_train_acc = sum(train_accuracy) / len(train_accuracy)\n",
    "        \n",
    "        ''' Model evalutation'''\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_losses = []\n",
    "            val_accuracy = []\n",
    "            for img, label in val_loader:\n",
    "                img, label = img.to(DEVICE), label.to(DEVICE)\n",
    "                logits = model(img)\n",
    "                loss = criterion(logits, label)\n",
    "                acc = acc_fn(logits, label)\n",
    "                val_losses.append(loss.item())\n",
    "                val_accuracy.append(acc.item())\n",
    "            avg_val_loss = sum(val_losses) / len(val_losses)\n",
    "            avg_val_acc = sum(val_accuracy) / len(val_accuracy)        \n",
    "        \n",
    "        print(f\"train_loss: {avg_train_loss:.4f} - train_accuracy: {avg_train_acc:.4f}\")\n",
    "        print(f\"validation_loss: {avg_val_loss:.4f} - validation_accuracy: {avg_val_acc:.4f}\")\n",
    "        print(f\"ETA: {time_left}\")\n",
    "\n",
    "        # Update learning rate\n",
    "        prev_lr = lr_scheduler.get_last_lr()[0]\n",
    "        lr_scheduler.step()\n",
    "        curr_lr = lr_scheduler.get_last_lr()[0]\n",
    "        \n",
    "        if prev_lr > curr_lr:  \n",
    "            print(f'Updating lr {prev_lr}->{curr_lr}')\n",
    "        \n",
    "        # Update best model on validation set\n",
    "        if avg_val_acc > best_accuracy_val:\n",
    "            best_accuracy_val = avg_val_acc\n",
    "            torch.save(model, output_model_path)\n",
    "\n",
    "        writer.add_scalars('cls/loss', {'train' : avg_train_loss, 'val' : avg_val_loss}, global_step=epoch)\n",
    "        writer.add_scalars('cls/acc', {'train' : avg_train_acc, 'val' : avg_val_acc}, global_step=epoch)\n",
    "        \n",
    "        # Early stopping\n",
    "        if early_stopper.early_stop(avg_val_loss):\n",
    "            print(f'Stopping early at Epoch {epoch + 1}, min val loss failed to decrease after {early_stopper.get_patience()} epochs')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_run(model, optimizer, train_loader, val_loader, criterion, acc_fn, lr_scheduler, early_stopper, num_epochs, output_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
